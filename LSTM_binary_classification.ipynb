{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QbSDs6-BLfxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51355eef-146d-4ccb-9d18-5f2f03ec882a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uvqKlblVc9Z",
        "outputId": "f0230c9c-1f0d-4a7f-9f27-2b41613c6f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Download stopwords (if not already installed)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/INST 750/Assignment 1/IMDB Dataset.csv')\n",
        "\n",
        "# Initialize stopwords\n",
        "english_stops = set(stopwords.words('english'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    df = data.copy()\n",
        "    x_data = df['review']\n",
        "    y_data = df['sentiment']\n",
        "\n",
        "    # Pre-processing\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex=True)\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex=True)\n",
        "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])\n",
        "\n",
        "    # ENCODE SENTIMENT -> 0 & 1\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data\n"
      ],
      "metadata": {
        "id": "jX-Z9m68w_B2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "x_data, y_data = load_dataset()\n",
        "\n",
        "# First split: 75% train, 25% temp (validation + test)\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(x_data, y_data, test_size=0.25, random_state=42, stratify=y_data)\n",
        "\n",
        "# Second split: 15% validation, 10% test (relative to full dataset)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.4, random_state=42, stratify=y_temp)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxHatMv4xDoH",
        "outputId": "acdba692-2bfa-4a09-9fb6-99ee510b4af8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-f0ac7048b9c8>:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_data = y_data.replace('negative', 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dataset sizes\n",
        "print(f\"Training Set Size: {len(x_train)}\")\n",
        "print(f\"Validation Set Size: {len(x_val)}\")\n",
        "print(f\"Test Set Size: {len(x_test)}\")\n",
        "\n",
        "print('\\nTrain Set')\n",
        "print(x_train[:5], '\\n')\n",
        "print(y_train[:5], '\\n')\n",
        "\n",
        "print('Validation Set')\n",
        "print(x_val[:5], '\\n')\n",
        "print(y_val[:5], '\\n')\n",
        "\n",
        "print('Test Set')\n",
        "print(x_test[:5], '\\n')\n",
        "print(y_test[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-sQdcFLxGr8",
        "outputId": "25df89e0-36c0-4f63-e0af-e56f55d34747"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Size: 37500\n",
            "Validation Set Size: 7500\n",
            "Test Set Size: 5000\n",
            "\n",
            "Train Set\n",
            "17949    [i, saw, adam, had, four, sons, first, time, t...\n",
            "5786     [i, one, shamelessly, enjoyed, every, episode,...\n",
            "42175    [this, movie, journey, mind, screenwriter, cau...\n",
            "39484    [this, absolutely, one, best, movies, i, seen,...\n",
            "34209    [oh, geez, there, many, films, i, want, see, i...\n",
            "Name: review, dtype: object \n",
            "\n",
            "17949    0\n",
            "5786     1\n",
            "42175    1\n",
            "39484    1\n",
            "34209    0\n",
            "Name: sentiment, dtype: int64 \n",
            "\n",
            "Validation Set\n",
            "11066    [the, good, thing, movie, created, made, hungr...\n",
            "19236    [i, provided, location, services, film, every,...\n",
            "49911    [after, empire, strikes, back, return, jedi, s...\n",
            "16692    [this, one, creepy, movie, creepier, anything,...\n",
            "27069    [the, saddest, thing, tribute, almost, singers...\n",
            "Name: review, dtype: object \n",
            "\n",
            "11066    0\n",
            "19236    1\n",
            "49911    1\n",
            "16692    1\n",
            "27069    0\n",
            "Name: sentiment, dtype: int64 \n",
            "\n",
            "Test Set\n",
            "43988    [i, watched, movie, last, week, sometime, bigg...\n",
            "41806    [i, know, i, picked, movie, watch, strange, ti...\n",
            "14501    [every, i, rent, action, adventure, film, way,...\n",
            "17688    [the, world, sci, fi, drama, soylent, green, c...\n",
            "20997    [having, seen, a, perfect, spy, mini, series, ...\n",
            "Name: review, dtype: object \n",
            "\n",
            "43988    0\n",
            "41806    1\n",
            "14501    0\n",
            "17688    1\n",
            "20997    1\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to determine max review length\n",
        "def get_max_length():\n",
        "    review_length = [len(review) for review in x_train]\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ],
      "metadata": {
        "id": "yIvl073-xKoA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENCODE REVIEW\n",
        "token = Tokenizer(lower=False)\n",
        "token.fit_on_texts(x_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_val = token.texts_to_sequences(x_val)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "# Determine max sequence length\n",
        "max_length = get_max_length()\n",
        "\n",
        "# Pad sequences\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_val = pad_sequences(x_val, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1\n",
        "\n",
        "print('\\nEncoded X Train\\n', x_train[:5], '\\n')\n",
        "print('Encoded X Validation\\n', x_val[:5], '\\n')\n",
        "print('Encoded X Test\\n', x_test[:5], '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKlVPWI-xPhy",
        "outputId": "a9595f7d-8b89-4916-c17b-fca0bf6c9c4d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Encoded X Train\n",
            " [[    1   119  1871  2891   575  3358    23    10    66  3067     1   164\n",
            "   2026   234  8395  8206   575  3358   111  9331  2181   575   786     4\n",
            "   2847  8723   993  1871 38735  3458  1113   133  3042    12   453   705\n",
            "   1816   116 21973  1317 25546    33     6 25546 38735  3358  2655    85\n",
            "    204     1   323    70  5675  2107   664   210   434    31   571 34663\n",
            "    124   819  4798 21974    87   143  2664 11685   202    49     5  7536\n",
            "   5497   508 11685 18768  9089   148  5449     5   387  1417    72   444\n",
            "    140   199   780     7   308 23055   145    84   206   732   695     1\n",
            "     92   321     1  1245   856  2026 27135  8395  8206  2847  8723  2053\n",
            "    196  1540   285   232    80     2  3358    20 13185  6224  3043   767\n",
            "     43   124    48   566  3043  1582    89 13185  2656  8723]\n",
            " [    1     5  8607   410    83   298  4015 12395   773   339   859  3622\n",
            "   4318    54  9904     9    46  3976  3675  2542  5451  3414   554   403\n",
            "    931   519 38736  1842  7082   880  9332     6    40 21975  3955  2767\n",
            "    247  1410  1513   340  4911  1420  3976    42 10712  3512     9  2219\n",
            "   5756   331   665   691  1135 10884   870    29   197   299  2601    46\n",
            "   2767  3976 38736   246 10712  1852   691  3112  2616   490  4358  7862\n",
            "   3976   211  3826  2112   247    21    63    42     2    46    69  2047\n",
            "    653   935     9  2219    26     1   275   153     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [    8     3  1158   228  2625   946 27137  3878    59 13770    51 29128\n",
            "    805     1     1     7  7699    98  2507  4016    50 44724   221  1066\n",
            "    853  1485 34664     6 23056  2848   419  4319   157 38737  1660   729\n",
            "    452  7152    58     4    15 15992   227   216 18769  1090    99   365\n",
            "    829  2602  4583   244   244   576  5720  6225   938   193   404  1410\n",
            "    353   227   173    63    76    56  5721  3495  2768    62   142 55357\n",
            "  25547   454  8608   664  5498     1 44725  1066    14  1301  3956     7\n",
            "  31593 11071    85  6953     2 15605     3    94   657    81   582   443\n",
            "   1899   443   449  2321    36   532  5798   814  6036 38738     3    24\n",
            "    104  2913  5148     3    55  1184  2542  3957    91    16     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [    8   327     5    45    28     1    37   225   270  2948    39   905\n",
            "     86   725  5534  2130  1623    63     1   259   365    29  1491 13771\n",
            "   2263   149    96    52   295    96   377     1    20    98   174  1563\n",
            "    248   892     2   421    13  2609   845   894  1272     2   115  5239\n",
            "    237 14439  3941  1129    10   182     2  1881  3676    52 38739  1413\n",
            "     22   620     8    22    14  1882    38  2691  4611    99    10    34\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [  331 14797    50    38    35     1    92    15     1   103  1443  5499\n",
            "   2502   363  1018     1   234    34    46     1  1043  2804  1837   150\n",
            "    567   113  5401     2    46     9   385  8028    29   935     5    51\n",
            "    103   434    11  1312   838     6   947   121    42   496   107   509\n",
            "      8     5    73   106   302   212   236  8307    14   270   839   123\n",
            "    541   307  2834   120    29   127    66     6   984   141  7083  5935\n",
            "    135     8     5   117     1  2985    65     4   107   443   106    45\n",
            "      1   285   112  2036  4359  4527   407   200     1    58   186     5\n",
            "    645  1492   233     7    76   120  8724 11686   219     6   796   676\n",
            "      1    30   950   216   141 11687   821     9  2006     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]] \n",
            "\n",
            "Encoded X Validation\n",
            " [[    2     9    66     3   959    24  4720  1641  4185  4898   247   553\n",
            "    418     2     3     5   811     1    37   104    10   169  1641  4185\n",
            "    619  1367   362     1   932   156   405   445  1641  4185   562  1883\n",
            "    353  1452  1569    58    61   212   470   527   186  1768   813  1641\n",
            "   4185     1    34    44   520    62  8024    96   503   143    97   114\n",
            "    255   368     1  3577  1641  4185  2282   420  5422  1641  4185  2269\n",
            "   1464   188    80  2336  1601  6154     1    41    37  5422  1641  4185\n",
            "   2269  1744     7   384    90   268    95   139    16   718    44   283\n",
            "    718     3    62 34284  1559    19  1641  4185     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [    1  2028  1381  6963     4    83  2651    12  1112  1186  7193  4225\n",
            "    511  6830    51  4643  1522   410   122   976   142   468  5038 10775\n",
            "   3602  1077 78992    86     4 17698  2883  8024   731  7089   795   535\n",
            "  22313  6301    83   142     5    55    47    40  1186    40   108  4839\n",
            "     20   444   699  5064   976   997  1027 45133    39     9     4    22\n",
            "    795   825    86    77  1738   310 22902   807   295  1974    60  2292\n",
            "      2   409    81  7375 24151 30841   223  1131  1186   342  6164  5655\n",
            "    189   234   409    81  1736  8754   409    81    57 13731    39  3414\n",
            "   1035   578  3707 33192    55    15     4 16808    25   717    15   771\n",
            "     26  2963  5196  2106 16100   974   257  5326  1206  4177  5120   460\n",
            "     98     1    12   665  1527   700  1717  8073  7193  4225]\n",
            " [  300  3611  3792    63   921  9195   238   440     3   230  1589   110\n",
            "   2731   320   510  8089  4316 13136   293    10 25385  3611   931  4890\n",
            "     82   624  1516     6   817   233   230    55  1516  2592   360  3993\n",
            "     54  4664  9493  1314  8482  3887 14885 15936    82   233   230   261\n",
            "    397    38 41991  1065    24  7237  1172   883 12709   845 13136  5893\n",
            "   2165   646  2731 13136  6249 20446  8089    42    59   319  1172   883\n",
            "  12709  3826 13136    84  1257 13136  1665 21709   136   675  8089  4316\n",
            "    317  5893 12803  8089    57  5504 81221 19420  1633 13136  2754 28656\n",
            "     20   426 13136  6924  1857   169  1857   417   510  8089  4316    76\n",
            "    696   291   706    15    75  2795 17367  6273     2   357 13136  2105\n",
            "  17367  1257   218  4297  8089  1247   149 28656  2603  2731]\n",
            " [    8     5   881     3 16265   138   511  1928   185    22    68  5194\n",
            "    136   569   459    73   427     7   444  1022 26321  4007  1305    59\n",
            "    437  2329   817  6547    96   158  2270  1467  2174   277    21   491\n",
            "   5220    59    20  2174   172   107  1909   390  2474    77  4951     2\n",
            "    127   257  4432    88   316  2600   115   421   137   243  2146  1308\n",
            "   1724   397   842   177  1241   984   502  1399    79     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [    2  9300    66  3201   123  5322   481   822   873   909  1912  3373\n",
            "    219   979   127   128  6159  2919  1530  3920   313   123 38330 27637\n",
            "   6159 51340   263  2770  3712  3197  2074  1814  2130  1623     5   281\n",
            "     15  1719 71277    25  4198  2154  1371  7155  1052 24555 21155   717\n",
            "   1932     1  1719   201  1366     7   467    38   147  2492  3370  9219\n",
            "   2252   512   620  8283   731    78   236    78   124   411  4950 31112\n",
            "    120    55   706   406   261 25435  6159   406 25435    86   807   163\n",
            "      6  5127    25   280  5705    49  6159  3201     1   162  2154  2154\n",
            "   4594 21728   283 78500   998  1794   120  3197  1049   792   475   355\n",
            "   5322  2554 11521  4601   519    46     7  6159  3201  2885  1906   763\n",
            "     13    26    93   109   254   446    27   337  3905  2219]] \n",
            "\n",
            "Encoded X Test\n",
            " [[    1   195     3   142  1165  5405  1024   324   104     2    43     4\n",
            "     90   862  4198   838  2835    26     2   804   162  1614     4  6223\n",
            "   1085 54616  7814   753    30   290  3370  7646   227   392  3936  2452\n",
            "  24849  2565    33 17729   248    32   101    30   280   387   102  1268\n",
            "   3237 20032 24628    83  1339     2    54  1281     4   327  4370    20\n",
            "   1269     1   288   479   394  1644   404  3394   659    25    30   387\n",
            "   7382   539     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [    1    47     1  1486     3    34   581   322  2809   480     6    61\n",
            "    181    83     9   260     4   996   181  2411   249   488   596   399\n",
            "      4   325   181   114   362     4  3885     1   746    54     4     1\n",
            "   1610     3    22    29    64     1    98    44   825    33   868    13\n",
            "     76   365   339    87   376    16    54     1    30   196  3401     4\n",
            "     27    26  1895     5    29    76    22   708     9   823  1939 32108\n",
            "     67   293 13996     3   307    19   190    16   216    87    80   493\n",
            "    459   467     1   154  1707  1205   272   474     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [   83     1   716   113  1091     4    26  5554 13170   228    78   556\n",
            "      8     1   885  1192  2828   382     4    76   324  2145 44187     5\n",
            "    386     1   147   678  4203     2  2795  3607  5045  6091    28    17\n",
            "    191    49   323     1  1451     4     1   363  2208   116  4659   203\n",
            "     84     1   103     1   363     2    43    61   246   313   756   316\n",
            "  18060   298  5056   104    44  1731   676    18  1537  1861  5994  2340\n",
            "    441    50   205   694    84 13174   733  1218    19    90     9    67\n",
            "    199    18   341   388   645    90 19754  1492     6  1558  1549    35\n",
            "     19     3  4240   113    43   478   798 20637   123   832    44    94\n",
            "   5056   104  1766    10    68 26478 19334   771    54     3     1   518\n",
            "    956    65   238    10  1388   534   117  5056   104  2490]\n",
            " [    2    85   761   750   348  8653  1260    27   217  4504     7    85\n",
            "     82   751   432  4043 11063  1291   846   198 23975   787 15800   198\n",
            "    104  3502  4602  1603 28185  2476     2   339   173  1603  2036   347\n",
            "   8653  1260    31   768  1603   424    13    24   143   805   385  3311\n",
            "    567  1977    57  1689     4   350  1230  5196   551    25   561    25\n",
            "    561  8864  5266   310 15485 14529  1217   173   524   490   248  4639\n",
            "   4176  2277 12221   106   414 12221  1796   864  8653  6489    21  1750\n",
            "   1603 18929    21 20943 18503    64    66  5266  2174  3990  2429   490\n",
            "  12221 14560   191    59   124    81   259   996 26780 11394   176  2278\n",
            "   1048  4467  1395   374  1249  1168 11481 21156    85   234     6   107\n",
            "   4467   589  8653  1260  6469   568  1429   285  5266   602]\n",
            " [ 1599    37    39   318  2605  2115   110     5    62     5    78 68807\n",
            "      5  2516   954   796  1004  2699 12165 33318 16309    91   181  2240\n",
            "     49 33318 16309  2152 13896 16309  2217    46   277    67  1400     5\n",
            "     58   767  3332    14   556   377   187   161  7386   711 21885   374\n",
            "    603  3881 21885   208   125   347 21405 26930  3099  9483   908    21\n",
            "      6   736    16   326   196   100   304     2     5    97   296  2427\n",
            "    454  2152  6690 38945    41 11297   420  2605 10021   475    53   300\n",
            "   1433    42    96   503  1270   296    76   529   376 10021   353  1142\n",
            "   2544  1077   178    76   318  2605  6690 38945  1760    32   849    42\n",
            "   1270   296   764    19    63   632  5637  2597 33397    59 87420    11\n",
            "     41    19   138  7425   456  9077  6825  2605  3629   196]] \n",
            "\n",
            "Maximum review length:  130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xb8T54klWfTg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "PxcGxFKfWiAK",
        "outputId": "154c4990-8e86-4a88-e589-98c99677853e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ARCHITECTURE\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(total_words, EMBED_DIM, input_length=max_length),\n",
        "    LSTM(LSTM_OUT, dropout=0.3, recurrent_dropout=0.3),  # ✅ Added dropout to prevent overfitting\n",
        "    Dense(1, activation='sigmoid')  # ✅ Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "L6NCfOtWWpY_"
      },
      "outputs": [],
      "source": [
        "# CHECKPOINTING\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gytzJCUzWrna",
        "outputId": "558ff624-8ee1-4da2-d654-bded35455b23"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.5323 - loss: 0.6896\n",
            "Epoch 1: val_loss improved from inf to 0.66679, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 158ms/step - accuracy: 0.5324 - loss: 0.6895 - val_accuracy: 0.5876 - val_loss: 0.6668\n",
            "Epoch 2/10\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.5805 - loss: 0.6650\n",
            "Epoch 2: val_loss improved from 0.66679 to 0.65813, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 144ms/step - accuracy: 0.5805 - loss: 0.6650 - val_accuracy: 0.5984 - val_loss: 0.6581\n",
            "Epoch 3/10\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6562 - loss: 0.6285\n",
            "Epoch 3: val_loss improved from 0.65813 to 0.53901, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 147ms/step - accuracy: 0.6563 - loss: 0.6284 - val_accuracy: 0.7628 - val_loss: 0.5390\n",
            "Epoch 4/10\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7326 - loss: 0.5646\n",
            "Epoch 4: val_loss improved from 0.53901 to 0.53124, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 143ms/step - accuracy: 0.7326 - loss: 0.5646 - val_accuracy: 0.7647 - val_loss: 0.5312\n",
            "Epoch 5/10\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7752 - loss: 0.5096\n",
            "Epoch 5: val_loss improved from 0.53124 to 0.49014, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 144ms/step - accuracy: 0.7752 - loss: 0.5095 - val_accuracy: 0.7921 - val_loss: 0.4901\n",
            "Epoch 6/10\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7851 - loss: 0.4911\n",
            "Epoch 6: val_loss improved from 0.49014 to 0.40894, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 144ms/step - accuracy: 0.7851 - loss: 0.4909 - val_accuracy: 0.8404 - val_loss: 0.4089\n",
            "Epoch 7/10\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.8679 - loss: 0.3444\n",
            "Epoch 7: val_loss improved from 0.40894 to 0.39795, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 141ms/step - accuracy: 0.8679 - loss: 0.3444 - val_accuracy: 0.8539 - val_loss: 0.3980\n",
            "Epoch 8/10\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8959 - loss: 0.2850\n",
            "Epoch 8: val_loss improved from 0.39795 to 0.37282, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 161ms/step - accuracy: 0.8960 - loss: 0.2850 - val_accuracy: 0.8556 - val_loss: 0.3728\n",
            "Epoch 9/10\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.9253 - loss: 0.2171\n",
            "Epoch 9: val_loss did not improve from 0.37282\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 146ms/step - accuracy: 0.9253 - loss: 0.2171 - val_accuracy: 0.8595 - val_loss: 0.3815\n",
            "Epoch 10/10\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.9437 - loss: 0.1699\n",
            "Epoch 10: val_loss did not improve from 0.37282\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 147ms/step - accuracy: 0.9436 - loss: 0.1699 - val_accuracy: 0.8599 - val_loss: 0.3916\n"
          ]
        }
      ],
      "source": [
        "# TRAINING\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATE MODEL\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"LSTM Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "GIvQMOGqqPjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda788cc-e7ff-4b4a-eed9-83404ad4fcae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8800 - loss: 0.3403\n",
            "LSTM Test Accuracy: 0.8668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTIONS\n",
        "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# CALCULATE CORRECT & WRONG PREDICTIONS\n",
        "correct = np.sum(y_pred.flatten() == y_test)\n",
        "wrong = len(y_pred) - correct\n",
        "\n",
        "print(f'Correct Predictions: {correct}')\n",
        "print(f'Wrong Predictions: {wrong}')\n",
        "print(f'Final Accuracy: {correct / len(y_pred) * 100:.2f}%')"
      ],
      "metadata": {
        "id": "nvKDvI7JuTHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8ad6e1-529c-41a9-8808-f5336d71cbec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step\n",
            "Correct Predictions: 4334\n",
            "Wrong Predictions: 666\n",
            "Final Accuracy: 86.68%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}